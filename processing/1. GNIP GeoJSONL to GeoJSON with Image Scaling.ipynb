{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all of the pieces together, this Notebook handles GNIP GeoJSONL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, pprint, os, io, sys, PIL,urllib.request\n",
    "import pandas as pd; import numpy as np\n",
    "from IPython.display import display, Image\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the configuration file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_file = \"hajj.config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_date': '2016-09-07',\n",
      " 'tweets': '/data/hajj/gnip_tweets_full.jsonl',\n",
      " 'web_root': '/data/www/tweetsonamap/hajj'}\n"
     ]
    }
   ],
   "source": [
    "config = json.load(open(config_file,'r'))\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-09-07 00:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = pd.Timestamp(config['start_date'] + \"T00:00:000Z\")\n",
    "start_date # Ensure this is UTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in jsonl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "with open(config['tweets'],'r') as inFile:\n",
    "    for line in inFile:\n",
    "        tweets.append(json.loads(line.strip()))\n",
    "df = pd.DataFrame(tweets)\n",
    "df = pd.DataFrame(df[df['twitter_extended_entities'].notnull()])\n",
    "df['id'] = df.id.apply(lambda x: x.split(\":\")[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of tweets: geo-tagged and geolocated. Identify these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Identified 86 geotagged tweets and 1962 geolocated tweets (2048 total)'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geotagged_df  = df[df.geo.notnull()].copy()\n",
    "geolocated_df = df[df.geo.isnull()].copy()\n",
    "\n",
    "\"Identified {0} geotagged tweets and {1} geolocated tweets ({2} total)\".format(len(geotagged_df),len(geolocated_df), len(geolocated_df)+len(geotagged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process all of the images\n",
    "\n",
    "First, get the raw img_url for all of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['img_url'] = df.twitter_extended_entities.apply(lambda r: r['media'][0]['media_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(config['web_root']+\"/map_images\"):\n",
    "    os.makedirs(config['web_root']+\"/map_images\")\n",
    "\n",
    "map_image_dir = config['web_root']+\"/map_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizes = {\"thumb\":60,\n",
    "         \"small\":150,\n",
    "         \"medium\":300,\n",
    "         \"large\":400,\n",
    "         \"original\":-1 #basewidth value won't be used\n",
    "        }\n",
    "\n",
    "def download_and_resize(url, tweet_id):\n",
    "    \"\"\"\n",
    "        Input: URL to image\n",
    "        Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    img_name = tweet_id + \".jpg\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as img:\n",
    "            f = io.BytesIO(img.read())\n",
    "            orig_img = PIL.Image.open(f)\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print(e,\"Error on:\",url)\n",
    "        print(sys.exc_info())\n",
    "\n",
    "    # Iterate over each size/basewidth\n",
    "    for size,basewidth in sizes.items():\n",
    "\n",
    "        # Make directory within map_image_dir for each size\n",
    "        if not os.path.exists(map_image_dir+size):\n",
    "            os.makedirs(map_image_dir+size)\n",
    "            print(\"making directory for\",size)\n",
    "\n",
    "        # Set filename to save resized image and break to the next image if it already exists\n",
    "        new_path = map_image_dir+size+\"/\"+img_name\n",
    "        if os.path.isfile(new_path):\n",
    "            break\n",
    "\n",
    "        # Don't resize images in original folder\n",
    "        if size == \"original\":\n",
    "            orig_img.save(new_path)\n",
    "        else:\n",
    "            try:\n",
    "                # Set height proportional to fixed basewidth from \n",
    "                # https://opensource.com/life/15/2/resize-images-python\n",
    "                wpercent = (basewidth / float(orig_img.size[0]))\n",
    "                hsize = int((float(orig_img.size[1]) * float(wpercent))) \n",
    "                resized_img = orig_img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)\n",
    "                resized_img.save(new_path)\n",
    "#                     display(Image(filename=orig_path, width=basewidth, height=hsize)) # display resized image\n",
    "            except:\n",
    "                e = sys.exc_info()[0]\n",
    "                print(e,\"Error on:\",img_name)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37: 773490012331577344, http://pbs.twimg.com/media/CrXkDEuXYAQZg8Q.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.error.HTTPError'> Error on: http://pbs.twimg.com/media/CrXkDEuXYAQZg8Q.jpg\n",
      "(<class 'urllib.error.HTTPError'>, HTTPError(), <traceback object at 0x7f86d3d0de48>)\n",
      "<class 'UnboundLocalError'> Error on: 773490012331577344.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 798: 774730112566697984, http://pbs.twimg.com/media/CsA87z3XYAA8X4z.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.error.HTTPError'> Error on: http://pbs.twimg.com/media/CsA87z3XYAA8X4z.jpg\n",
      "(<class 'urllib.error.HTTPError'>, HTTPError(), <traceback object at 0x7f86d8507948>)\n",
      "<class 'UnboundLocalError'> Error on: 774730112566697984.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 1800: 775772519324381184, http://pbs.twimg.com/media/CsPu6HwXgAAtX_O.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.error.HTTPError'> Error on: http://pbs.twimg.com/media/CsPu6HwXgAAtX_O.jpg\n",
      "(<class 'urllib.error.HTTPError'>, HTTPError(), <traceback object at 0x7f86d87a2108>)\n",
      "<class 'UnboundLocalError'> Error on: 775772519324381184.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2012: 776121452760367104, http://pbs.twimg.com/media/CsVV2IXWgAAVbUS.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.error.HTTPError'> Error on: http://pbs.twimg.com/media/CsVV2IXWgAAVbUS.jpg\n",
      "(<class 'urllib.error.HTTPError'>, HTTPError(), <traceback object at 0x7f86d3deaa88>)\n",
      "<class 'UnboundLocalError'> Error on: 776121452760367104.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2425: 777198381890502656, http://pbs.twimg.com/media/CsjlXHPWgAAETbA.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.error.HTTPError'> Error on: http://pbs.twimg.com/media/CsjlXHPWgAAETbA.jpg\n",
      "(<class 'urllib.error.HTTPError'>, HTTPError(), <traceback object at 0x7f86d3e22048>)\n",
      "<class 'UnboundLocalError'> Error on: 777198381890502656.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 2501: 778019121069953026, http://pbs.twimg.com/media/CswUQfkWgAAEaTw.jpg"
     ]
    }
   ],
   "source": [
    "for idx, tweet in df.iterrows():\n",
    "    download_and_resize(tweet.img_url, tweet.id)\n",
    "    sys.stderr.write(\"\\r {0}: {1}, {2}\".format(idx, tweet.id, tweet.img_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Write these geojson files\n",
    "\n",
    "### First, the geotagged tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feats = []\n",
    "for idx, tweet in geotagged_df.iterrows():\n",
    "    if os.path.exists(map_image_dir+\"/thumb/\"+tweet.id+\".jpg\"):\n",
    "        jsonObj = {  \"type\"       : \"Feature\",\n",
    "                     \"geometry\"   : {  \"type\" : \"Point\", \n",
    "                                       \"coordinates\" : list(reversed(tweet['geo']['coordinates']))},\n",
    "                     \"properties\" : {  \"id\" : tweet.id,\n",
    "                                       \"user\" : tweet['actor']['preferredUsername'],\n",
    "                                       \"text\" : tweet['body'],\n",
    "                                       \"day\" : int( ( pd.Timestamp(tweet['postedTime']) - start_date ).total_seconds() /(3600*24) )\n",
    "           }\n",
    "         }\n",
    "        feats.append(jsonObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(config['web_root']+'/geotagged-tweets.geojson','w') as outFile:\n",
    "    json.dump({'type':\"FeatureCollection\",\"features\":feats},outFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, the geolocated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geolocated_df['location_string'] = geolocated_df.location.apply(lambda x: str(x['geo']['coordinates']))\n",
    "#TODO: Should filter this based on whether or not the image was downloaded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_loc = geolocated_df.groupby('location_string').aggregate({\n",
    "        'id' : {\n",
    "            'Tweets' : 'count',\n",
    "            'IDs'    : lambda x: [y for y in x.values]\n",
    "         },\n",
    "        'body': {\n",
    "            'text'   : lambda x: [y for y in x.values]\n",
    "         },\n",
    "        'postedTime' : {\n",
    "            'day'   : lambda x: [int( ( pd.Timestamp(y) - start_date ).total_seconds() /(3600*24) ) for y in x.values]\n",
    "         },\n",
    "        'actor'      : {\n",
    "            'user'   : lambda x: [y['preferredUsername'] for y in x.values]\n",
    "         },\n",
    "        'location' : {\n",
    "            'geojson'     : lambda x: x.values[0]['geo'],\n",
    "            'displayName' : lambda x: x.values[0]['displayName']\n",
    "         }\n",
    "    })\n",
    "gb_loc.columns = gb_loc.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>day</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>IDs</th>\n",
       "      <th>geojson</th>\n",
       "      <th>displayName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_string</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[[[42.010156, 19.471337], [42.010156, 27.574819], [48.217206, 27.574819], [48.217206, 19.471337]]]</th>\n",
       "      <td>[حج مبرور و سعي مشكور \\nاهلا ضيوف الرحمن https...</td>\n",
       "      <td>[bashry_bkb, zozo_2432, riyadiyatv, awtannews,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>502</td>\n",
       "      <td>[773401676841648128, 773417749796225024, 77343...</td>\n",
       "      <td>{'coordinates': [[[42.010156, 19.471337], [42....</td>\n",
       "      <td>الرياض, المملكة العربية السعودية</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[[39.571438, 21.165831], [39.571438, 21.613835], [40.031935, 21.613835], [40.031935, 21.165831]]]</th>\n",
       "      <td>[SS1:I WANT TO LOSE#WEIGHT,BY CYCLE OR GO TO F...</td>\n",
       "      <td>[paradiseticket1, vip50133, 1412Mshmsh, alshad...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, ...</td>\n",
       "      <td>209</td>\n",
       "      <td>[773314636242378752, 773326875024326656, 77332...</td>\n",
       "      <td>{'coordinates': [[[39.571438, 21.165831], [39....</td>\n",
       "      <td>مكة المكرمة, المملكة العربية السعودية</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 text  \\\n",
       "location_string                                                                                         \n",
       "[[[42.010156, 19.471337], [42.010156, 27.574819...  [حج مبرور و سعي مشكور \\nاهلا ضيوف الرحمن https...   \n",
       "[[[39.571438, 21.165831], [39.571438, 21.613835...  [SS1:I WANT TO LOSE#WEIGHT,BY CYCLE OR GO TO F...   \n",
       "\n",
       "                                                                                                 user  \\\n",
       "location_string                                                                                         \n",
       "[[[42.010156, 19.471337], [42.010156, 27.574819...  [bashry_bkb, zozo_2432, riyadiyatv, awtannews,...   \n",
       "[[[39.571438, 21.165831], [39.571438, 21.613835...  [paradiseticket1, vip50133, 1412Mshmsh, alshad...   \n",
       "\n",
       "                                                                                                  day  \\\n",
       "location_string                                                                                         \n",
       "[[[42.010156, 19.471337], [42.010156, 27.574819...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "[[[39.571438, 21.165831], [39.571438, 21.613835...  [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, ...   \n",
       "\n",
       "                                                    Tweets  \\\n",
       "location_string                                              \n",
       "[[[42.010156, 19.471337], [42.010156, 27.574819...     502   \n",
       "[[[39.571438, 21.165831], [39.571438, 21.613835...     209   \n",
       "\n",
       "                                                                                                  IDs  \\\n",
       "location_string                                                                                         \n",
       "[[[42.010156, 19.471337], [42.010156, 27.574819...  [773401676841648128, 773417749796225024, 77343...   \n",
       "[[[39.571438, 21.165831], [39.571438, 21.613835...  [773314636242378752, 773326875024326656, 77332...   \n",
       "\n",
       "                                                                                              geojson  \\\n",
       "location_string                                                                                         \n",
       "[[[42.010156, 19.471337], [42.010156, 27.574819...  {'coordinates': [[[42.010156, 19.471337], [42....   \n",
       "[[[39.571438, 21.165831], [39.571438, 21.613835...  {'coordinates': [[[39.571438, 21.165831], [39....   \n",
       "\n",
       "                                                                              displayName  \n",
       "location_string                                                                            \n",
       "[[[42.010156, 19.471337], [42.010156, 27.574819...       الرياض, المملكة العربية السعودية  \n",
       "[[[39.571438, 21.165831], [39.571438, 21.613835...  مكة المكرمة, المملكة العربية السعودية  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_loc.sort_values(by='Tweets', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "regions = []\n",
    "for idx, row in gb_loc.copy().iterrows():\n",
    "    \n",
    "    json_obj = {'type':'Feature',\n",
    "                'properties' : {\n",
    "                        'count'       : row['Tweets'],\n",
    "                        'tweets'      : [],\n",
    "                        'displayName' : row['displayName']\n",
    "                },\n",
    "                'geometry'  : row['geojson']\n",
    "               }\n",
    "    \n",
    "    #Stupid Twitter --> They only have 4 coordinates, need to make it a valid polygon\n",
    "    json_obj['geometry']['coordinates'][0].append(json_obj['geometry']['coordinates'][0][0])\n",
    "    \n",
    "    for idx, tweet_id in enumerate(row['IDs']):\n",
    "        \n",
    "        json_obj['properties']['tweets'].append({\n",
    "                 'id': tweet_id,\n",
    "                 'text': row['text'][idx],\n",
    "                 'user': row['user'][idx],\n",
    "                 'day':  row['day'][idx]\n",
    "            })\n",
    "        \n",
    "    regions.append(json_obj)\n",
    "print(len(regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geojson_feature_collection = {'type':\"FeatureCollection\", \"features\" : regions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(config['web_root']+'/image-tweets-by-polygon.geojson','w') as out:\n",
    "    json.dump(geojson_feature_collection,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third, Write tweets per day CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-09-07</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-08</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-09</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-10</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-11</th>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id\n",
       "day            \n",
       "2016-09-07   91\n",
       "2016-09-08   99\n",
       "2016-09-09  199\n",
       "2016-09-10  299\n",
       "2016-09-11  449"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format: 2016-09-25,140008                                                                                                                   \n",
    "\n",
    "df['day'] = df.postedTime.apply(lambda x: pd.Timestamp(x).date())\n",
    "gb_day = df.groupby('day').agg({'id': 'count'})\n",
    "gb_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(config['web_root']+\"/tweets_per_day.csv\",'w') as tweetsPerDayOut:\n",
    "    tweetsPerDayOut.write(\"postedDate2,count\\n\")\n",
    "    for idx, r in gb_day.iterrows():\n",
    "        tweetsPerDayOut.write(str(r.name)+\",\"+str(r.id)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost Done... Now go run Stage 2!\n",
    "Stage 2 handles the geo metadata and creates more point geojsons with turf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
