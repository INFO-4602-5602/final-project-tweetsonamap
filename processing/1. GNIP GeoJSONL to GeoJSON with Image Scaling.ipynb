{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting all of the pieces together, this Notebook handles GNIP GeoJSONL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, pprint, os, io, sys, PIL,urllib.request\n",
    "import pandas as pd; import numpy as np\n",
    "from IPython.display import display, Image\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where is the configuration file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_file = \"hajj.config\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_date': '2016-09-07',\n",
      " 'tweets': '/data/hajj/gnip_tweets_full.jsonl',\n",
      " 'web_root': '/data/www/tweetsonamap/hajj'}\n"
     ]
    }
   ],
   "source": [
    "config = json.load(open(config_file,'r'))\n",
    "start_date = pd.Timestamp(config['start_date'])\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Read in jsonl file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "with open(config['tweets'],'r') as inFile:\n",
    "    for line in inFile:\n",
    "        tweets.append(json.loads(line.strip()))\n",
    "df = pd.DataFrame(tweets)\n",
    "df = df[df['twitter_extended_entities'].notnull()]\n",
    "df['id'] = df.id.apply(lambda x: x.split(\":\")[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two types of tweets: geo-tagged and geolocated. Identify these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Identified 86 geotagged tweets and 1962 geolocated tweets (2048 total)'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geotagged_df  = df[df.geo.notnull()].copy()\n",
    "geolocated_df = df[df.geo.isnull()].copy()\n",
    "\n",
    "\"Identified {0} geotagged tweets and {1} geolocated tweets ({2} total)\".format(len(geotagged_df),len(geolocated_df), len(geolocated_df)+len(geotagged_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Process all of the images\n",
    "\n",
    "First, get the raw img_url for all of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['img_url'] = df.twitter_extended_entities.apply(lambda r: r['media'][0]['media_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(config['web_root']+\"/map_images\"):\n",
    "    os.makedirs(config['web_root']+\"/map_images\")\n",
    "\n",
    "map_image_dir = config['web_root']+\"/map_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sizes = {\"thumb\":60,\n",
    "         \"small\":150,\n",
    "         \"medium\":300,\n",
    "         \"large\":400,\n",
    "         \"original\":-1 #basewidth value won't be used\n",
    "        }\n",
    "\n",
    "def download_and_resize(url, tweet_id):\n",
    "    \"\"\"\n",
    "        Input: URL to image\n",
    "        Returns: None\n",
    "    \"\"\"\n",
    "    \n",
    "    img_name = tweet_id + \".jpg\"\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as img:\n",
    "            f = io.BytesIO(img.read())\n",
    "            orig_img = PIL.Image.open(f)\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print(e,\"Error on:\",url)\n",
    "        print(sys.exc_info())\n",
    "\n",
    "    # Iterate over each size/basewidth\n",
    "    for size,basewidth in sizes.items():\n",
    "\n",
    "        # Make directory within map_image_dir for each size\n",
    "        if not os.path.exists(map_image_dir+size):\n",
    "            os.makedirs(map_image_dir+size)\n",
    "            print(\"making directory for\",size)\n",
    "\n",
    "        # Set filename to save resized image and break to the next image if it already exists\n",
    "        new_path = map_image_dir+size+\"/\"+img_name\n",
    "        if os.path.isfile(new_path):\n",
    "            break\n",
    "\n",
    "        # Don't resize images in original folder\n",
    "        if size == \"original\":\n",
    "            orig_img.save(new_path)\n",
    "        else:\n",
    "            try:\n",
    "                # Set height proportional to fixed basewidth from \n",
    "                # https://opensource.com/life/15/2/resize-images-python\n",
    "                wpercent = (basewidth / float(orig_img.size[0]))\n",
    "                hsize = int((float(orig_img.size[1]) * float(wpercent))) \n",
    "                resized_img = orig_img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)\n",
    "                resized_img.save(new_path)\n",
    "#                     display(Image(filename=orig_path, width=basewidth, height=hsize)) # display resized image\n",
    "            except:\n",
    "                e = sys.exc_info()[0]\n",
    "                print(e,\"Error on:\",img_name)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37: 773490012331577344, http://pbs.twimg.com/media/CrXkDEuXYAQZg8Q.jpg"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'urllib.error.HTTPError'> Error on: http://pbs.twimg.com/media/CrXkDEuXYAQZg8Q.jpg\n",
      "(<class 'urllib.error.HTTPError'>, HTTPError(), <traceback object at 0x7f86d3d0de48>)\n",
      "<class 'UnboundLocalError'> Error on: 773490012331577344.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 669: 774633256087990272, http://pbs.twimg.com/media/CsAM1T-UsAA62z6.jpg"
     ]
    }
   ],
   "source": [
    "for idx, tweet in df.iterrows():\n",
    "    download_and_resize(tweet.img_url, tweet.id)\n",
    "    sys.stderr.write(\"\\r {0}: {1}, {2}\".format(idx, tweet.id, tweet.img_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Write these geojson files\n",
    "\n",
    "### First, the geotagged tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = []\n",
    "for idx, tweet in geotagged.iterrows():\n",
    "    if os.path.exists(map_image_dir+\"/thumb/\"+tweet.id+\".jpg\"):\n",
    "        jsonObj = {  \"type\"       : \"Feature\",\n",
    "                     \"geometry\"   : {  \"type\" : \"Point\", \n",
    "                                       \"coordinates\" : list(reversed(t['geo']['coordinates']))},\n",
    "                     \"properties\" : {  \"id\" : tweet_id,\n",
    "                                       \"user\" : t['actor']['preferredUsername'],\n",
    "                                       \"text\" : t['body'],\n",
    "                                       \"day\" : int( ( pd.Timestamp(t['postedTime']) - start_date ).total_seconds() /(3600*24) )\n",
    "           }\n",
    "         }\n",
    "        feats.append(jsonObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(config['web_root']+\"/geotagged-tweets.geojson','w') as outFile:\n",
    "    json.dump({'type':\"FeatureCollection\",\"features\":feats},outFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second, the geolocated tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geolocated_df['location_string'] = geolocated_df.location.apply(lambda x: str(x['geo']['coordinates']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_loc = geolocated_df.groupby('location_string').aggregate({\n",
    "        'id' : {\n",
    "            'Tweets' : 'count',\n",
    "            'IDs'    : lambda x: [y.split(\":\")[2] for y in x.values]\n",
    "         },\n",
    "        'body': {\n",
    "            'text'   : lambda x: [y for y in x.values]\n",
    "         },\n",
    "        'postedTime' : {\n",
    "            'day'   : lambda x: [int( ( pd.Timestamp(y) - start_date ).total_seconds() /(3600*24) ) for y in x.values]\n",
    "         },\n",
    "        'actor'      : {\n",
    "            'user'   : lambda x: [y['preferredUsername'] for y in x.values]\n",
    "         },\n",
    "        'location' : {\n",
    "            'geojson'     : lambda x: x.values[0]['geo'],\n",
    "            'displayName' : lambda x: x.values[0]['displayName']\n",
    "         }\n",
    "    })\n",
    "gb_loc.columns = gb_loc.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gb_loc.sort_values(by='Tweets', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regions = []\n",
    "for idx, row in gb_loc.copy().iterrows():\n",
    "    \n",
    "    json_obj = {'type':'Feature',\n",
    "                'properties' : {\n",
    "                        'count'       : row['Tweets'],\n",
    "                        'tweets'      : [],\n",
    "                        'displayName' : row['displayName']\n",
    "                },\n",
    "                'geometry'  : row['geojson']\n",
    "               }\n",
    "    \n",
    "    #Stupid Twitter --> They only have 4 coordinates, need to make it a valid polygon\n",
    "    json_obj['geometry']['coordinates'][0].append(json_obj['geometry']['coordinates'][0][0])\n",
    "    \n",
    "    for idx, tweet_id in enumerate(row['IDs']):\n",
    "        \n",
    "        json_obj['properties']['tweets'].append({\n",
    "                 'id': tweet_id,\n",
    "                 'text': row['text'][idx],\n",
    "                 'user': row['user'][idx],\n",
    "                 'day':  row['day'][idx]\n",
    "            })\n",
    "        \n",
    "    regions.append(json_obj)\n",
    "print(len(regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geojson_feature_collection = {'type':\"FeatureCollection\", \"features\" : regions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(config['web_root']+'/image-tweets-by-polygon.geojson','w') as out:\n",
    "    json.dump(geojson_feature_collection,out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
