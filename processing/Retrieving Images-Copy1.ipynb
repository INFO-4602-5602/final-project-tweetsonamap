{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the images from the tweets and push to s3 for scalable CDN\n",
    "(Reference: https://github.com/INFO-4602-5602/final-project-tweetsonamap/issues/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo, json, pprint, urllib.request, os.path, sys\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the DB\n",
    "\n",
    "    client = pymongo.MongoClient('mongodb://epic-analytics.cs.colorado.edu')\n",
    "    db = client.matthew\n",
    "    print(db.collection_names())\n",
    "    tweets = db.tweets\n",
    "    print(tweets.count(), \"tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient('localhost')\n",
    "tweets = client['matthew'].tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Image Handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err_log = open('scraping_errors_twitter.log','w')\n",
    "\n",
    "class InstagramHandler(HTMLParser):\n",
    "    \"\"\"\n",
    "        Custom function to handle scraping images from Instagram... totally violates TOS, I think.\n",
    "    \"\"\"\n",
    "    def __init__(self, tweet_id):\n",
    "        self.image_url = None\n",
    "        self.tweet_id = tweet_id\n",
    "        self.directory = \"/data/infovis/instagram\"\n",
    "        super().__init__()\n",
    "        \n",
    "    def image_needed(self):\n",
    "        if os.path.exists(self.directory+\"/\"+self.tweet_id+\".jpg\"):\n",
    "            err_log.write(\"File Exists: \"+self.tweet_id+\"\\n\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag=='meta':\n",
    "            if attrs[0][1]=='og:image':\n",
    "                self.image_url = attrs[1][1]\n",
    "                try:\n",
    "                    req = urllib.request.urlopen(self.image_url)\n",
    "                    with open(self.directory+\"/\"+self.tweet_id+\".jpg\",'wb') as pic:\n",
    "                        pic.write(req.read())\n",
    "                except:\n",
    "                    err_log.write(\"Error, image not found: \"+self.tweet_id+\"\\n\")\n",
    "                    \n",
    "class TwitterHandler():\n",
    "    \"\"\"\n",
    "        Custom function to handle scraping images from Twitter...\n",
    "    \"\"\"\n",
    "    def __init__(self, tweet_id):\n",
    "        self.image_url = None\n",
    "        self.tweet_id = tweet_id\n",
    "        self.directory = \"/data/infovis/twitter\"\n",
    "        \n",
    "    def image_needed(self):\n",
    "        if os.path.exists(self.directory+\"/\"+self.tweet_id+\".jpg\"):\n",
    "            err_log.write(\"File Exists: \"+self.tweet_id+\"\\n\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def download(self, url):\n",
    "        print(url)\n",
    "        return url\n",
    "        try:\n",
    "            req = urllib.request.urlopen(url)\n",
    "            with open(self.directory+\"/\"+self.tweet_id+\".jpg\",'wb') as pic:\n",
    "                pic.write(req.read())\n",
    "        except:\n",
    "            err_log.write(\"Error, image not found: \"+self.tweet_id+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor = tweets.find({'geo' : {\"$exists\":True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_image_tweets = {\n",
    "    \"verb\":\"post\", # original tweet\n",
    "    \"twitter_extended_entities.media.0\":{\"$exists\":True}, # at least 1 media entity\n",
    "    \"twitter_extended_entities.media\": {\"$all\":[{\"$elemMatch\": { \"type\": \"photo\" }}]}, # all media entities are photos\n",
    "    \"location.geo.coordinates\":{\"$exists\":True} # has geolocation (not necessarily a point)\n",
    "}\n",
    "cursor = tweets.find(geo_image_tweets).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://pbs.twimg.com/media/CtKGGh_XgAAZiZB.jpg\n",
      "http://pbs.twimg.com/media/CtKGvDIUsAAO_ku.jpg\n",
      "http://pbs.twimg.com/media/CtKHV4yWIAABbJY.jpg\n",
      "http://pbs.twimg.com/media/CtKKt44VYAAIs5w.jpg\n",
      "http://pbs.twimg.com/media/CtKPWsrVMAAz1za.jpg\n",
      "http://pbs.twimg.com/media/B2hfaeSIMAEJq5d.jpg\n",
      "http://pbs.twimg.com/media/BuR8ET2IcAEY1aR.jpg\n",
      "http://pbs.twimg.com/media/CtKUcX-VMAA9ENY.jpg\n",
      "http://pbs.twimg.com/media/CtKWEuiXEAArmSP.jpg\n",
      "http://pbs.twimg.com/media/CtKW9zhUAAAuzfa.jpg\n"
     ]
    }
   ],
   "source": [
    "idx = 0;\n",
    "for t in cursor:\n",
    "    tweet_id = t['id'].split(\":\")[2]\n",
    "    for m, entities in t['twitter_extended_entities'].items():\n",
    "        for idx, entity in enumerate(entities):\n",
    "            downloader = TwitterHandler(tweet_id)\n",
    "            if downloader.image_needed():\n",
    "                downloader.download(entity['media_url'])\n",
    "                    \n",
    "        #Instagram Case\n",
    "#         if url['expanded_url'].startswith(\"https://www.instagram.com\"):            \n",
    "#             parser = InstagramHandler(tweet_id)\n",
    "#             if parser.image_needed():\n",
    "#                 try:\n",
    "#                     req = urllib.request.urlopen(url['expanded_url'])\n",
    "#                     parser.feed(req.read().decode('utf-8'))\n",
    "#                 except:\n",
    "#                     err_log.write(\"Error, page not found: \"+tweet_id + \"\\n\")\n",
    "\n",
    "    #Twitter Case\n",
    "err_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
