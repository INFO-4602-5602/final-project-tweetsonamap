{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting geotagged tweets to GEOJSON\n",
    "\n",
    "1. Connect to the database and identify all tweets that are geolocated to a Polygon rather than a point.\n",
    "1. Group these together and generate a GeoJSON Feature Collection of Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo, json, pprint, urllib.request, os.path, sys, json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client': 'epic-analytics.cs.colorado.edu',\n",
      " 'collection': 'tweets',\n",
      " 'database': 'matthew',\n",
      " 'img_root': 'http://epic-analytics.cs.colorado.edu:9000/jennings/infovis/map_images',\n",
      " 'start_date': '2016-9-25',\n",
      " 'web_root': '/data/www/jennings/infovis'}\n"
     ]
    }
   ],
   "source": [
    "config = json.load(open('tweets-on-a-map.config','r'))\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the database, per the config information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13830253 tweets \n"
     ]
    }
   ],
   "source": [
    "client = pymongo.MongoClient('mongodb://'+config['client'])\n",
    "db = client[config['database']]\n",
    "tweets = db[config['collection']]\n",
    "print(\"Found {0} tweets \".format(tweets.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Location` tag, not point locations\n",
    "\n",
    "1. Query for just tweets with images (photos) and a `location.geo` field then put them into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_image_tweets = {\n",
    "    \"verb\":\"post\",\n",
    "    \"twitter_extended_entities.media.0\":{\"$exists\":True}, # at least 1 media entity\n",
    "    \"twitter_extended_entities.media\": {\"$all\":[{\"$elemMatch\": { \"type\": \"photo\" }}]}, # all media entities are photos\n",
    "    \"location.geo.coordinates\":{\"$exists\":True} # has geolocation (not necessarily a point)\n",
    "}\n",
    "df = pd.DataFrame(list(tweets.find(geo_image_tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that this worked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23789\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>actor</th>\n",
       "      <th>body</th>\n",
       "      <th>datetime</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>favoritesCount</th>\n",
       "      <th>generator</th>\n",
       "      <th>geo</th>\n",
       "      <th>gnip</th>\n",
       "      <th>id</th>\n",
       "      <th>...</th>\n",
       "      <th>object</th>\n",
       "      <th>objectType</th>\n",
       "      <th>postedTime</th>\n",
       "      <th>provider</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>twitter_entities</th>\n",
       "      <th>twitter_extended_entities</th>\n",
       "      <th>twitter_filter_level</th>\n",
       "      <th>twitter_lang</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58c1e007d8991e9a470000a9</td>\n",
       "      <td>{'utcOffset': '-18000', 'statusesCount': 25329...</td>\n",
       "      <td>Mood: 3 months from now when we touchdown in J...</td>\n",
       "      <td>{'$date': 1474761687000}</td>\n",
       "      <td>[0, 70]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'link': 'http://twitter.com/download/iphone',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'matching_rules': [{'id': 9056142625283655206...</td>\n",
       "      <td>tag:search.twitter.com,2005:779833156773871616</td>\n",
       "      <td>...</td>\n",
       "      <td>{'id': 'object:search.twitter.com,2005:7798331...</td>\n",
       "      <td>activity</td>\n",
       "      <td>2016-09-25 00:01:27</td>\n",
       "      <td>{'link': 'http://www.twitter.com', 'displayNam...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'urls': [], 'symbols': [], 'media': [{'media_...</td>\n",
       "      <td>{'media': [{'media_url_https': 'https://pbs.tw...</td>\n",
       "      <td>low</td>\n",
       "      <td>en</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58c1e008d8991e9a470001cc</td>\n",
       "      <td>{'utcOffset': None, 'statusesCount': 22931, 'l...</td>\n",
       "      <td>ACTUALIZACIÓN \\nBoletín 8pm \\nEl CNH aumenta a...</td>\n",
       "      <td>{'$date': 1474761856000}</td>\n",
       "      <td>[0, 116]</td>\n",
       "      <td>0</td>\n",
       "      <td>{'link': 'http://twitter.com/download/android'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'matching_rules': [{'id': 2199701286811376328...</td>\n",
       "      <td>tag:search.twitter.com,2005:779833865082843136</td>\n",
       "      <td>...</td>\n",
       "      <td>{'id': 'object:search.twitter.com,2005:7798338...</td>\n",
       "      <td>activity</td>\n",
       "      <td>2016-09-25 00:04:16</td>\n",
       "      <td>{'link': 'http://www.twitter.com', 'displayNam...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'urls': [], 'symbols': [], 'media': [{'media_...</td>\n",
       "      <td>{'media': [{'media_url_https': 'https://pbs.tw...</td>\n",
       "      <td>low</td>\n",
       "      <td>es</td>\n",
       "      <td>post</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  58c1e007d8991e9a470000a9   \n",
       "1  58c1e008d8991e9a470001cc   \n",
       "\n",
       "                                               actor  \\\n",
       "0  {'utcOffset': '-18000', 'statusesCount': 25329...   \n",
       "1  {'utcOffset': None, 'statusesCount': 22931, 'l...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Mood: 3 months from now when we touchdown in J...   \n",
       "1  ACTUALIZACIÓN \\nBoletín 8pm \\nEl CNH aumenta a...   \n",
       "\n",
       "                   datetime display_text_range  favoritesCount  \\\n",
       "0  {'$date': 1474761687000}            [0, 70]               0   \n",
       "1  {'$date': 1474761856000}           [0, 116]               0   \n",
       "\n",
       "                                           generator  geo  \\\n",
       "0  {'link': 'http://twitter.com/download/iphone',...  NaN   \n",
       "1  {'link': 'http://twitter.com/download/android'...  NaN   \n",
       "\n",
       "                                                gnip  \\\n",
       "0  {'matching_rules': [{'id': 9056142625283655206...   \n",
       "1  {'matching_rules': [{'id': 2199701286811376328...   \n",
       "\n",
       "                                               id  ...   \\\n",
       "0  tag:search.twitter.com,2005:779833156773871616  ...    \n",
       "1  tag:search.twitter.com,2005:779833865082843136  ...    \n",
       "\n",
       "                                              object objectType  \\\n",
       "0  {'id': 'object:search.twitter.com,2005:7798331...   activity   \n",
       "1  {'id': 'object:search.twitter.com,2005:7798338...   activity   \n",
       "\n",
       "           postedTime                                           provider  \\\n",
       "0 2016-09-25 00:01:27  {'link': 'http://www.twitter.com', 'displayNam...   \n",
       "1 2016-09-25 00:04:16  {'link': 'http://www.twitter.com', 'displayNam...   \n",
       "\n",
       "  retweetCount                                   twitter_entities  \\\n",
       "0            0  {'urls': [], 'symbols': [], 'media': [{'media_...   \n",
       "1            0  {'urls': [], 'symbols': [], 'media': [{'media_...   \n",
       "\n",
       "                           twitter_extended_entities  twitter_filter_level  \\\n",
       "0  {'media': [{'media_url_https': 'https://pbs.tw...                   low   \n",
       "1  {'media': [{'media_url_https': 'https://pbs.tw...                   low   \n",
       "\n",
       "  twitter_lang  verb  \n",
       "0           en  post  \n",
       "1           es  post  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create something to group by on (can't group by the location column, as it's not hashable :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['location_string'] = df.location.apply(lambda x: str(x['geo']['coordinates']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now group by Geometries. This method is okay because order is preserved with rows in between groups \n",
    "http://stackoverflow.com/questions/26456125/python-pandas-is-order-preserved-when-using-groupby-and-agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp(config['start_date'])\n",
    "gb_loc = df.groupby('location_string').aggregate({\n",
    "        'id' : {\n",
    "            'Tweets' : 'count',\n",
    "            'IDs'    : lambda x: [y.split(\":\")[2] for y in x.values]\n",
    "         },\n",
    "        'body': {\n",
    "            'text'   : lambda x: [y for y in x.values]\n",
    "         },\n",
    "        'postedTime' : {\n",
    "            'day'   : lambda x: [int( ( pd.Timestamp(y) - start_date ).total_seconds() /(3600*24) ) for y in x.values]\n",
    "         },\n",
    "        'actor'      : {\n",
    "            'user'   : lambda x: [y['preferredUsername'] for y in x.values]\n",
    "         },\n",
    "        'location' : {\n",
    "            'geojson'     : lambda x: x.values[0]['geo'],\n",
    "            'displayName' : lambda x: x.values[0]['displayName']\n",
    "         }\n",
    "    })\n",
    "gb_loc.columns = gb_loc.columns.droplevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that this worked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDs</th>\n",
       "      <th>Tweets</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>day</th>\n",
       "      <th>geojson</th>\n",
       "      <th>displayName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location_string</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[[[-87.634643, 24.396308], [-87.634643, 31.001056], [-79.974307, 31.001056], [-79.974307, 24.396308]]]</th>\n",
       "      <td>[780024297909653504, 780103153597423616, 78013...</td>\n",
       "      <td>1419</td>\n",
       "      <td>[9/25/2016 8:00 AM EDT Tropical Weather Update...</td>\n",
       "      <td>[TheWxReporter, karadapena, EricaABryan, hanna...</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 4, 4, 4, 4, ...</td>\n",
       "      <td>{'coordinates': [[[-87.634643, 24.396308], [-8...</td>\n",
       "      <td>Florida, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[[[-84.952008, 19.82646], [-84.952008, 23.594925], [-74.131649, 23.594925], [-74.131649, 19.82646]]]</th>\n",
       "      <td>[779838282410528768, 779845609415118849, 77984...</td>\n",
       "      <td>958</td>\n",
       "      <td>[Seguimos..! Camagüey, cuba! https://t.co/HxkA...</td>\n",
       "      <td>[benq_09, KarelBecerra, KarelBecerra, JLucasMo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>{'coordinates': [[[-84.952008, 19.82646], [-84...</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  IDs  \\\n",
       "location_string                                                                                         \n",
       "[[[-87.634643, 24.396308], [-87.634643, 31.0010...  [780024297909653504, 780103153597423616, 78013...   \n",
       "[[[-84.952008, 19.82646], [-84.952008, 23.59492...  [779838282410528768, 779845609415118849, 77984...   \n",
       "\n",
       "                                                    Tweets  \\\n",
       "location_string                                              \n",
       "[[[-87.634643, 24.396308], [-87.634643, 31.0010...    1419   \n",
       "[[[-84.952008, 19.82646], [-84.952008, 23.59492...     958   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "location_string                                                                                         \n",
       "[[[-87.634643, 24.396308], [-87.634643, 31.0010...  [9/25/2016 8:00 AM EDT Tropical Weather Update...   \n",
       "[[[-84.952008, 19.82646], [-84.952008, 23.59492...  [Seguimos..! Camagüey, cuba! https://t.co/HxkA...   \n",
       "\n",
       "                                                                                                 user  \\\n",
       "location_string                                                                                         \n",
       "[[[-87.634643, 24.396308], [-87.634643, 31.0010...  [TheWxReporter, karadapena, EricaABryan, hanna...   \n",
       "[[[-84.952008, 19.82646], [-84.952008, 23.59492...  [benq_09, KarelBecerra, KarelBecerra, JLucasMo...   \n",
       "\n",
       "                                                                                                  day  \\\n",
       "location_string                                                                                         \n",
       "[[[-87.634643, 24.396308], [-87.634643, 31.0010...  [0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 3, 4, 4, 4, 4, ...   \n",
       "[[[-84.952008, 19.82646], [-84.952008, 23.59492...  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, ...   \n",
       "\n",
       "                                                                                              geojson  \\\n",
       "location_string                                                                                         \n",
       "[[[-87.634643, 24.396308], [-87.634643, 31.0010...  {'coordinates': [[[-87.634643, 24.396308], [-8...   \n",
       "[[[-84.952008, 19.82646], [-84.952008, 23.59492...  {'coordinates': [[[-84.952008, 19.82646], [-84...   \n",
       "\n",
       "                                                     displayName  \n",
       "location_string                                                   \n",
       "[[[-87.634643, 24.396308], [-87.634643, 31.0010...  Florida, USA  \n",
       "[[[-84.952008, 19.82646], [-84.952008, 23.59492...          Cuba  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_loc.sort_values(by='Tweets', ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build GeoJSON Objects for each region. This is not atomic, it creates a copy to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regions = []\n",
    "for idx, row in gb_loc.copy().iterrows():\n",
    "    \n",
    "    json_obj = {'type':'Feature',\n",
    "                'properties' : {\n",
    "                        'count'       : row['Tweets'],\n",
    "                        'tweets'      : [],\n",
    "                        'displayName' : row['displayName']\n",
    "                },\n",
    "                'geometry'  : row['geojson']\n",
    "               }\n",
    "    \n",
    "    #Stupid Twitter --> They only have 4 coordinates, need to make it a valid polygon\n",
    "    json_obj['geometry']['coordinates'][0].append(json_obj['geometry']['coordinates'][0][0])\n",
    "    \n",
    "    for idx, tweet_id in enumerate(row['IDs']):\n",
    "        \n",
    "        json_obj['properties']['tweets'].append({\n",
    "                 'id': tweet_id,\n",
    "                 'text': row['text'][idx],\n",
    "                 'user': row['user'][idx],\n",
    "                 'day':  row['day'][idx]\n",
    "            })\n",
    "        \n",
    "    regions.append(json_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4525\n"
     ]
    }
   ],
   "source": [
    "print(len(regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store this as a geojson feature collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geojson_feature_collection = {'type':\"FeatureCollection\", \"features\" : regions}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write this feature collection to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/data/www/jennings/infovis/image-tweets-by-polygon.geojson','w') as out:\n",
    "    json.dump(geojson_feature_collection,out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><hr>\n",
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geometry': {'coordinates': [[[-0.019481, 51.525469],\n",
       "    [-0.019481, 51.564174],\n",
       "    [0.069473, 51.564174],\n",
       "    [0.069473, 51.525469],\n",
       "    [-0.019481, 51.525469]]],\n",
       "  'type': 'Polygon'},\n",
       " 'properties': {'count': 4,\n",
       "  'displayName': 'Stratford, London',\n",
       "  'tweets': [{'id': '783803471657046020',\n",
       "    'text': '#prayforhaiti https://t.co/wOh1jIlFBW',\n",
       "    'thumb': 'http://epic-analytics.cs.colorado.edu:9000/jennings/infovis/map_images/thumb/783803471657046020.jpg',\n",
       "    'time': '2016-10-05T22:58:04.000000000',\n",
       "    'user': 'symnicola'},\n",
       "   {'id': '785327831375089665',\n",
       "    'text': '#ebook \\n#talent \\n#jamaica \\n#screenwriting\\n#Scotland \\n#Soldier\\n#Police\\n#filmmaking \\nhttps://t.co/hZXw96olfh https://t.co/mJZRxeQKE0',\n",
       "    'thumb': 'http://epic-analytics.cs.colorado.edu:9000/jennings/infovis/map_images/thumb/785327831375089665.jpg',\n",
       "    'time': '2016-10-10T03:55:20.000000000',\n",
       "    'user': 'rhpanton'},\n",
       "   {'id': '786588675731628032',\n",
       "    'text': 'Enter our @Crowdrise sweepstakes &amp; help children and families in #Haiti #HurricaneMatthew https://t.co/3YStKhSprb https://t.co/d0871e3sJg',\n",
       "    'thumb': 'http://epic-analytics.cs.colorado.edu:9000/jennings/infovis/map_images/thumb/786588675731628032.jpg',\n",
       "    'time': '2016-10-13T15:25:29.000000000',\n",
       "    'user': 'lumos'},\n",
       "   {'id': '786965097436635136',\n",
       "    'text': 'Après l’ouragan: comment aider le peuple haitien de se récupérer #Haiti https://t.co/oqnnfPggNV https://t.co/L8uyGF6S7i',\n",
       "    'thumb': 'http://epic-analytics.cs.colorado.edu:9000/jennings/infovis/map_images/thumb/786965097436635136.jpg',\n",
       "    'time': '2016-10-14T16:21:14.000000000',\n",
       "    'user': 'lumos'}]},\n",
       " 'type': 'Feature'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
